# Databricks 14 Days AI Challenge ğŸš€

This repository documents my **daily learnings, notes, and hands-on implementations**
from the **Databricks 14 Days AI Challenge**.

The goal of this challenge is to progressively build skills in **Databricks, Apache Spark,
and data engineering**, moving from foundations to production-grade pipelines.

---

## ğŸ“‚ Repository Structure

Each `Day-XX` folder contains:
- A `README.md` explaining the concepts learned
- Code files (`.py` / notebooks) with hands-on implementation

---

## ğŸ”§ Tools & Technologies
- Databricks
- Apache Spark
- PySpark
- SQL
- Delta Lake
- Lakehouse Architecture

---

## ğŸ¯ Learning Objectives
- Understand distributed data processing using Spark
- Gain hands-on experience with Databricks notebooks
- Apply data transformations on real-world datasets
- Build reliable, scalable, and production-ready data pipelines
- Maintain a well-documented learning repository

---

## ğŸ“… Challenge Progress

### âœ… Phase 1: Foundations (Completed)
- âœ… Day 01: Databricks Overview & Lakehouse Architecture  
- âœ… Day 02: Apache Spark Fundamentals  
- âœ… Day 03: PySpark Transformations Deep Dive  
- âœ… Day 04: Delta Lake Introduction  

### ğŸš€ Phase 2: Data Engineering (In Progress)
- âœ… Day 05: Delta Lake Advanced (Time Travel, MERGE, OPTIMIZE, VACUUM)  
- âœ… Day 06: Medallion Architecture (Bronzeâ€“Silverâ€“Gold)  
- â³ Upcoming: Spark SQL Advanced, Performance Optimization, Delta Lake Internals  

---

## ğŸ”— Connect
This repository is part of my **learning-in-public journey**.  
Progress and insights are shared regularly on LinkedIn.
