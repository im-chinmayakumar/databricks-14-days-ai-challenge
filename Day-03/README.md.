# Day 3 (11/01/26) â€“ PySpark Transformations Deep Dive ğŸš€

## ğŸ“Œ Overview
Day 3 focused on a deeper understanding of **PySpark transformations** and how Spark enables scalable data processing compared to traditional tools like Pandas. The session emphasized joins, window functions, and feature engineering using PySpark.

---

## ğŸ“˜ What I Learned

- **PySpark vs Pandas**  
  Pandas is suitable for small datasets, while PySpark is built for distributed processing and handles large-scale data efficiently.

- **Joins (Inner, Left, Right, Outer)**  
  Learned how Spark performs joins across distributed datasets while maintaining performance and data integrity.

- **Window Functions**  
  Used window functions to calculate running totals and rankings without reducing data granularity.

- **User-Defined Functions (UDFs)**  
  Created custom transformations when built-in Spark functions were insufficient.

---

## ğŸ› ï¸ Hands-On Tasks

1. Loaded the full e-commerce dataset into Spark
2. Performed complex joins across multiple datasets
3. Calculated running totals using window functions
4. Created derived features for analytical use cases

---

## ğŸ§ª Practice & Implementation

The hands-on practice included:
- Applying PySpark transformations on large datasets
- Using window specifications for advanced analytics
- Implementing feature engineering logic using UDFs

(Code implementation available in the corresponding `.py` file / notebook.)

---

## ğŸ¯ Key Takeaways

- PySpark scales far beyond in-memory processing compared to Pandas
- Window functions enable advanced analytics without data loss
- UDFs add flexibility for custom business logic
- Transformations are the backbone of efficient Spark pipelines

---

## ğŸ”§ Tools & Technologies

- Databricks
- Apache Spark
- PySpark
- Spark SQL

---

## ğŸ“… Challenge Progress

- **Challenge:** Databricks 14 Days AI Challenge  
- **Day Completed:** Day 3

---

## ğŸ”œ Next Steps
- Explore Spark SQL in depth
- Optimize transformations for performance
- Work with Delta Lake for reliable data pipelines
